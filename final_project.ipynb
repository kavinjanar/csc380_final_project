{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cb06b4-f58d-46e0-8f71-b616bcc0512d",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "**Group HOMEWORK**. This final project can be collaborative. The maximum members of a group is 2. You can also work by yourself. Please respect the academic integrity. **Remember: if you get caught on cheating, you get F.**\n",
    "\n",
    "## A Introduction to the competition\n",
    "\n",
    "<img src=\"news-sexisme-EN.jpg\" alt=\"drawing\" width=\"380\"/>\n",
    "\n",
    "Sexism is a growing problem online. It can inflict harm on women who are targeted, make online spaces inaccessible and unwelcoming, and perpetuate social asymmetries and injustices. Automated tools are now widely deployed to find, and assess sexist content at scale but most only give classifications for generic, high-level categories, with no further explanation. Flagging what is sexist content and also explaining why it is sexist improves interpretability, trust and understanding of the decisions that automated tools use, empowering both users and moderators.\n",
    "\n",
    "This project is based on SemEval 2023 - Task 10 - Explainable Detection of Online Sexism (EDOS). [Here](https://codalab.lisn.upsaclay.fr/competitions/7124#learn_the_details-overview) you can find a detailed introduction to this task.\n",
    "\n",
    "You only need to complete **TASK A - Binary Sexism Detection: a two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist**. To cut down training time, we only use a subset of the original dataset (5k out of 20k). The dataset can be found in the same folder. \n",
    "\n",
    "Different from our previous homework, this competition gives you great flexibility (and very few hints), you can determine: \n",
    "-  how to preprocess the input text (e.g., remove emoji, remove stopwords, text lemmatization and stemming, etc.);\n",
    "-  which method to use to encode text features (e.g., TF-IDF, N-grams, Word2vec, GloVe, Part-of-Speech (POS), etc.);\n",
    "-  which model to use.\n",
    "\n",
    "## Requirements\n",
    "-  **Input**: the text for each instance.\n",
    "-  **Output**: the binary label for each instance.\n",
    "-  **Feature engineering**: use at least 2 different methods to extract features and encode text into numerical values.\n",
    "-  **Model selection**: implement with at least 3 different models and compare their performance.\n",
    "-  **Evaluation**: create a dataframe with rows indicating feature+model and columns indicating Precision, Accuracy and F1-score (using weighted average). Your results should have at least 6 rows (2 feature engineering methods x 3 models). Report best performance with (1) your feature engineering method, and (2) the model you choose. \n",
    "- **Format**: add explainations for each step (you can add markdown cells). At the end of the report, write a summary and answer the following questions: \n",
    "    - What preprocessing steps do you follow?\n",
    "    - How do you select the features from the inputs? \n",
    "    - Which model you use and what is the structure of your model?\n",
    "    - How do you train your model?\n",
    "    - What is the performance of your best model?\n",
    "    - What other models or feature engineering methods would you like to implement in the future?\n",
    "- **Two Rules**, violations will result in 0 points in the grade: \n",
    "    - Not allowed to use test set in the training: You CANNOT use any of the instances from test set in the training process. \n",
    "    - Not allowed to use any generative AI (e.g., ChatGPT). \n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The performance should be only evaluated on the test set (a total of 1086 instances). Please split original dataset into train set and test set. The test set should NEVER be used in the training process. The evaluation metric is a combination of precision, recall, and f1-score (use `classification_report` in sklearn). \n",
    "\n",
    "The total points are 10.0. Each team will compete with other teams in the class on their best performance. Points will be deducted if not following the requirements above. \n",
    "\n",
    "If ALL the requirements are met:\n",
    "- Top 25\\% teams: 10.0 points.\n",
    "- Top 25\\% - 50\\% teams: 8.5 points.\n",
    "- Top 50\\% - 75\\% teams: 7.0 points.\n",
    "- Top 75\\% - 100\\% teams: 6.0 points.\n",
    "\n",
    "If your best performance is above 0.80 (weighted F1-score) and meets all the requirements, you will also get full points (10.0 points). \n",
    "\n",
    "‚≠ê Bonus points will be awarded to top 5 teams (ranked by weighted F1-score):\n",
    "- Top 1 team: 3pt adding to final grade\n",
    "- Top 2 team: 2pt adding to final grade\n",
    "- Top 3-5 teams: 1pt adding to final grade\n",
    "\n",
    "## Submission\n",
    "Similar as homework, submit both a PDF and .ipynb version of the report. \n",
    "\n",
    "The report should include: \n",
    "- (a)code AND outputs\n",
    "- (b)explainations for each step \n",
    "- (c)individual experimental results AND combine them in a table \n",
    "- (d)summary \n",
    "\n",
    "The due date is **May 2, Thursday by 11:59pm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b9d1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d531a72-9bf7-4b20-b494-11816fdd26d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set (Features and Labels):\n",
      "                                                  text       label\n",
      "21   Fuck the niggers and the jews. Both have a his...  not sexist\n",
      "27   Well then good because someone has to knock he...      sexist\n",
      "35   #USA #Texas #Islam #Muslims #Islamization #Sha...  not sexist\n",
      "38   Yes, normal women want to be dominated. Social...      sexist\n",
      "44   She didn't have to be a bitch about it. She li...      sexist\n",
      "48   TL:DR unclear covered her in shit and now she ...  not sexist\n",
      "49   [USER] 'Tis true as the puff and pass lead to ...  not sexist\n",
      "55   LOL, a Canadian guy legally changed his gender...  not sexist\n",
      "57              You are an idiot. Read the whole book.  not sexist\n",
      "60   Just fucking lol. What does she know about a h...      sexist\n",
      "63   WarrnTanka is so butthurt over her DNA FUBAR, ...  not sexist\n",
      "69           I would pay to see her Ass Cracker. #nsfw      sexist\n",
      "70   Again do u agree with me that a building is le...  not sexist\n",
      "71   Miley moved to England and renounced her US ci...  not sexist\n",
      "76   I have some unwashed underwear she can sniff I...  not sexist\n",
      "82   if your daughter is socializing with blacks, a...  not sexist\n",
      "84   [USER] It isn't about #fraud. It is about dela...  not sexist\n",
      "89   I saw an IT thread where they were saying we a...  not sexist\n",
      "95   Yes he can only top men fuck non ugly women no...  not sexist\n",
      "100  I dont sell my body for sex or even plasma. My...  not sexist\n",
      "101           No. Please keep those burkas on. PLEASE!  not sexist\n",
      "102  Just as well! The average Jewish mother would ...  not sexist\n",
      "111  What an amazing personality! I bet he watched ...  not sexist\n",
      "114  Most men know instinctually the game. But thei...  not sexist\n",
      "116   Yet another Islamist scumbag heard from... [URL]  not sexist\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "\n",
    "df = pd.read_csv('edos_labelled_data.csv')\n",
    "\n",
    "train_df = df[df['split'] == 'train']\n",
    "test_df = df[df['split'] == 'test']\n",
    "\n",
    "X_train = train_df['text']\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df['text']\n",
    "Y_test = test_df['label']\n",
    "\n",
    "train_table = pd.concat([X_train, Y_train], axis=1)\n",
    "test_table = pd.concat([X_test, Y_test], axis=1)\n",
    "\n",
    "print(\"Testing Set (Features and Labels):\")\n",
    "print(test_table.head(n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33ee1128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set (Features and Labels):\n",
      "                                                  text       label\n",
      "21   fuck the nigger and the jew both have a histor...  not sexist\n",
      "27   well then good because someone ha to knock her...      sexist\n",
      "35   usa texas islam muslim islamization sharialaw ...  not sexist\n",
      "38   yes normal woman want to be dominated social s...      sexist\n",
      "44   she didnt have to be a bitch about it she lite...      sexist\n",
      "48   tldr unclear covered her in shit and now she i...  not sexist\n",
      "49   user ti true a the puff and pas lead to the mu...  not sexist\n",
      "55   lol a canadian guy legally changed his gender ...  not sexist\n",
      "57                you are an idiot read the whole book  not sexist\n",
      "60   just fucking lol what doe she know about a har...      sexist\n",
      "63   warrntanka is so butthurt over her dna fubar s...  not sexist\n",
      "69              i would pay to see her as cracker nsfw      sexist\n",
      "70   again do u agree with me that a building is le...  not sexist\n",
      "71   miley moved to england and renounced her u cit...  not sexist\n",
      "76   i have some unwashed underwear she can sniff i...  not sexist\n",
      "82   if your daughter is socializing with black and...  not sexist\n",
      "84   user it isnt about fraud it is about delay try...  not sexist\n",
      "89   i saw an it thread where they were saying we a...  not sexist\n",
      "95   yes he can only top men fuck non ugly woman no...  not sexist\n",
      "100  i dont sell my body for sex or even plasma my ...  not sexist\n",
      "101               no please keep those burka on please  not sexist\n",
      "102  just a well the average jewish mother would ca...  not sexist\n",
      "111  what an amazing personality i bet he watched a...  not sexist\n",
      "114  most men know instinctually the game but their...  not sexist\n",
      "116        yet another islamist scumbag heard from url  not sexist\n"
     ]
    }
   ],
   "source": [
    "# Text Pre processing\n",
    "def text_preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    return text\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(text_preprocessing)\n",
    "test_df['text'] = test_df['text'].apply(text_preprocessing)\n",
    "\n",
    "X_train = train_df['text']\n",
    "Y_train = train_df['label']\n",
    "\n",
    "X_test = test_df['text']\n",
    "Y_test = test_df['label']\n",
    "\n",
    "train_table = pd.concat([X_train, Y_train], axis=1)\n",
    "test_table = pd.concat([X_test, Y_test], axis=1)\n",
    "\n",
    "print(\"Testing Set (Features and Labels):\")\n",
    "print(test_table.head(n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5a1129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the TF-IDF feature extraction method with N-grams\n",
    "\n",
    "tfidf_vectorizer_ngrams = TfidfVectorizer(ngram_range=(1, 2), max_features=6000)\n",
    "\n",
    "X_train_tfidf_ngrams = tfidf_vectorizer_ngrams.fit_transform(train_df['text'])\n",
    "\n",
    "X_test_tfidf_ngrams = tfidf_vectorizer_ngrams.transform(test_df['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e764015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with N-gram TF-IDF and Logistic Regression CV: 0.8130755064456722\n",
      "\n",
      "Classification Report with N-gram TF-IDF and Logistic Regression CV:\n",
      "Weighted F1 Score: 0.7946202825334021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.82      0.95      0.88       789\n",
      "      sexist       0.78      0.44      0.57       297\n",
      "\n",
      "    accuracy                           0.81      1086\n",
      "   macro avg       0.80      0.70      0.72      1086\n",
      "weighted avg       0.81      0.81      0.79      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training a Logistic Regression CV model with N-grams TF-IDF\n",
    "\n",
    "logRegNgram = LogisticRegressionCV(cv = 5, max_iter=10000, scoring='accuracy', multi_class='auto', Cs=10)\n",
    "logRegNgram.fit(X_train_tfidf_ngrams, Y_train)\n",
    "\n",
    "YPredLogRegNgram = logRegNgram.predict(X_test_tfidf_ngrams)\n",
    "\n",
    "print(\"Accuracy with N-gram TF-IDF and Logistic Regression CV:\", accuracy_score(Y_test, YPredLogRegNgram))\n",
    "print(\"\\nClassification Report with N-gram TF-IDF and Logistic Regression CV:\")\n",
    "\n",
    "report = classification_report(Y_test, YPredLogRegNgram, output_dict=True)\n",
    "weightedF1 = report['weighted avg']['f1-score']\n",
    "print(f\"Weighted F1 Score: {weightedF1}\")\n",
    "\n",
    "print(classification_report(Y_test, YPredLogRegNgram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "932f5376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 1.11\n",
      "Accuracy with SVM and N-Gram TF-IDF: 0.8195211786372008\n",
      "\n",
      "Classification Report with SVM and N-Gram TF-IDF:\n",
      "Weighted F1 Score: 0.8015049882873728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.82      0.96      0.89       789\n",
      "      sexist       0.80      0.45      0.58       297\n",
      "\n",
      "    accuracy                           0.82      1086\n",
      "   macro avg       0.81      0.71      0.73      1086\n",
      "weighted avg       0.82      0.82      0.80      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Support Vector Machine (SVM) model and N-Gram TF-IDF\n",
    "# BEST MODEL\n",
    "\n",
    "C_values = np.arange(1.08, 1.13, 0.01)\n",
    "cv_scores = []\n",
    "\n",
    "# Finding C value with the greatest accuracy\n",
    "\n",
    "# A sigmoid kernel had the best fit for the data\n",
    "for C in C_values:\n",
    "    clf = SVC(kernel='sigmoid', C=C)\n",
    "    scores = cross_val_score(clf, X_train_tfidf_ngrams, Y_train, cv=5)\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "max_accuracy = max(cv_scores)\n",
    "bestC = C_values[cv_scores.index(max_accuracy)]\n",
    "print(\"Best C value:\", bestC)\n",
    "svmModelNGram = SVC(kernel='sigmoid', C=bestC)\n",
    "\n",
    "svmModelNGram.fit(X_train_tfidf_ngrams, Y_train)\n",
    "\n",
    "YPredSVMNGram = svmModelNGram.predict(X_test_tfidf_ngrams)\n",
    "\n",
    "print(\"Accuracy with SVM and N-Gram TF-IDF:\", accuracy_score(Y_test, YPredSVMNGram))\n",
    "print(\"\\nClassification Report with SVM and N-Gram TF-IDF:\")\n",
    "report = classification_report(Y_test, YPredSVMNGram, output_dict=True)\n",
    "weightedF1 = report['weighted avg']['f1-score']\n",
    "print(f\"Weighted F1 Score: {weightedF1}\")\n",
    "print(classification_report(Y_test, YPredSVMNGram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71f26aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with MultinomialNB and TF-IDF N-Grams: 0.7412523020257827\n",
      "\n",
      "Classification Report with MultinomialNB and TF-IDF N-Grams:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.74      0.99      0.85       789\n",
      "      sexist       0.79      0.07      0.14       297\n",
      "\n",
      "    accuracy                           0.74      1086\n",
      "   macro avg       0.76      0.53      0.49      1086\n",
      "weighted avg       0.75      0.74      0.65      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a Multinomial Naive Bayes Model with TF-IDF N-Grams\n",
    "nbModel = MultinomialNB()\n",
    "nbModel.fit(X_train_tfidf_ngrams, Y_train)\n",
    "\n",
    "Y_predNB = nbModel.predict(X_test_tfidf_ngrams)\n",
    "\n",
    "print(\"Accuracy with MultinomialNB and TF-IDF N-Grams:\", accuracy_score(Y_test, Y_predNB))\n",
    "print(\"\\nClassification Report with MultinomialNB and TF-IDF N-Grams:\")\n",
    "print(classification_report(Y_test, Y_predNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c7e59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GloVe Feature extraction\n",
    "\n",
    "# loading the embeddings into a dictionary\n",
    "def loadGloveEmbeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "gloveEmbeddings = loadGloveEmbeddings('glove.twitter.27B.200d.txt')\n",
    "\n",
    "# converting the text to glove\n",
    "def textToGlove(text, embeddings, dim=200):\n",
    "    words = text.split()\n",
    "    vectors = [embeddings.get(word, np.zeros(dim)) for word in words]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "X_train_glove = np.array([textToGlove(text, gloveEmbeddings) for text in train_df['text']])\n",
    "X_test_glove = np.array([textToGlove(text, gloveEmbeddings) for text in test_df['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc26e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with LogisticRegressionCV: 0.7476979742173112\n",
      "\n",
      "Classification Report with LogisticRegressionCV:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.78      0.90      0.84       789\n",
      "      sexist       0.56      0.34      0.42       297\n",
      "\n",
      "    accuracy                           0.75      1086\n",
      "   macro avg       0.67      0.62      0.63      1086\n",
      "weighted avg       0.72      0.75      0.73      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using logistic regression CV with GloVe Feature extraction\n",
    "\n",
    "logRegCVGlove = LogisticRegressionCV(cv = 5, max_iter=1000, scoring='accuracy')\n",
    "\n",
    "logRegCVGlove.fit(X_train_glove, Y_train)\n",
    "\n",
    "Y_predCV = logRegCVGlove.predict(X_test_glove)\n",
    "print(\"Accuracy with LogisticRegressionCV:\", accuracy_score(Y_test, Y_predCV))\n",
    "print(\"\\nClassification Report with LogisticRegressionCV:\")\n",
    "print(classification_report(Y_test, Y_predCV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63d7edb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 1.09\n",
      "Accuracy with SVM and GloVe: 0.6988950276243094\n",
      "\n",
      "Classification Report with SVM and GloVe:\n",
      "Weighted F1 Score: 0.6636684641266078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.75      0.88      0.81       789\n",
      "      sexist       0.40      0.21      0.27       297\n",
      "\n",
      "    accuracy                           0.70      1086\n",
      "   macro avg       0.58      0.55      0.54      1086\n",
      "weighted avg       0.65      0.70      0.66      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training SVM with GloVe Feature Extraction\n",
    "C_values = np.arange(1.08, 1.13, 0.01)\n",
    "cv_scores = []\n",
    "\n",
    "# Finding C value with the greatest accuracy\n",
    "for C in C_values:\n",
    "    clf = SVC(kernel='sigmoid', C=C)\n",
    "    scores = cross_val_score(clf, X_train_glove, Y_train, cv=5)\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "max_accuracy = max(cv_scores)\n",
    "bestC = C_values[cv_scores.index(max_accuracy)]\n",
    "print(\"Best C value:\", bestC)\n",
    "svmModelGlove = SVC(kernel='sigmoid', C=bestC)\n",
    "\n",
    "svmModelGlove.fit(X_train_glove, Y_train)\n",
    "\n",
    "YPredSVMGlove = svmModelGlove.predict(X_test_glove)\n",
    "\n",
    "print(\"Accuracy with SVM and GloVe:\", accuracy_score(Y_test, YPredSVMGlove))\n",
    "print(\"\\nClassification Report with SVM and GloVe:\")\n",
    "report = classification_report(Y_test, YPredSVMGlove, output_dict=True)\n",
    "weightedF1 = report['weighted avg']['f1-score']\n",
    "print(f\"Weighted F1 Score: {weightedF1}\")\n",
    "print(classification_report(Y_test, YPredSVMGlove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb03f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with MultinomialNB and GloVe: 0.7265193370165746\n",
      "\n",
      "Classification Report with MultinomialNB and GloVe:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.73      1.00      0.84       789\n",
      "      sexist       0.00      0.00      0.00       297\n",
      "\n",
      "    accuracy                           0.73      1086\n",
      "   macro avg       0.36      0.50      0.42      1086\n",
      "weighted avg       0.53      0.73      0.61      1086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Multinomial NB with GloVe extraction\n",
    "\n",
    "# Normalize GloVe vectors to a range between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the training and test data\n",
    "X_train_glove_normalized = scaler.fit_transform(X_train_glove)\n",
    "X_test_glove_normalized = scaler.transform(X_test_glove)\n",
    "\n",
    "\n",
    "nb_model_glove = MultinomialNB()\n",
    "\n",
    "nb_model_glove.fit(X_train_glove_normalized, Y_train)\n",
    "\n",
    "Y_pred_nb_glove = nb_model_glove.predict(X_test_glove_normalized)\n",
    "\n",
    "print(\"Accuracy with MultinomialNB and GloVe:\", accuracy_score(Y_test, Y_pred_nb_glove))\n",
    "print(\"\\nClassification Report with MultinomialNB and GloVe:\")\n",
    "print(classification_report(Y_test, Y_pred_nb_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "938de456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Logistic Regression Model with TF-IDF N-gram Extraction ***********\n",
      "\n",
      "Sexist: precision=0.7764705882352941 recall=0.4444444444444444 F1-score=0.5653104925053534\n",
      "Non-Sexist: precision=0.8198689956331878 recall=0.9518377693282636 F1-score=0.8809384164222874\n",
      "Weighted Average: precision=0.808000370405587 recall=0.8130755064456722 F1-score=0.7946202825334021\n",
      "\n",
      "\n",
      "********** BEST MODEL: SVM Model with TF-IDF N-gram Extraction ***********\n",
      "\n",
      "Sexist: precision=0.7988165680473372 recall=0.45454545454545453 F1-score=0.5793991416309013\n",
      "Non-Sexist: precision=0.8233369683751364 recall=0.9569074778200254 F1-score=0.8851113716295428\n",
      "Weighted Average: precision=0.8166311130368709 recall=0.8195211786372008 F1-score=0.8015049882873728\n",
      "\n",
      "\n",
      "********** Multinomial NB with TF-IDF N-gram Extraction ***********\n",
      "\n",
      "Sexist: precision=0.7857142857142857 recall=0.07407407407407407 F1-score=0.13538461538461538\n",
      "Non-Sexist: precision=0.7400756143667296 recall=0.9923954372623575 F1-score=0.8478613968597726\n",
      "Weighted Average: precision=0.7525569084645419 recall=0.7412523020257827 F1-score=0.6530127743016495\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reports of all models using the TF-IDF N grams extraction method\n",
    "\n",
    "report = classification_report(Y_test, YPredLogRegNgram, output_dict=True)\n",
    "precisionSexist = report['sexist']['precision']\n",
    "recallSexist = report['sexist']['recall']\n",
    "f1ScoreSexist = report['sexist']['f1-score']\n",
    "\n",
    "precisionNonSexist = report['not sexist']['precision']\n",
    "recallNonSexist = report['not sexist']['recall']\n",
    "f1ScoreNonSexist = report['not sexist']['f1-score']\n",
    "\n",
    "precisionWeighted = report['weighted avg']['precision']\n",
    "recallWeighted = report['weighted avg']['recall']\n",
    "f1ScoreWeighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print('********** Logistic Regression Model with TF-IDF N-gram Extraction ***********\\n')\n",
    "print(f'Sexist: precision={precisionSexist} recall={recallSexist} F1-score={f1ScoreSexist}')\n",
    "print(f'Non-Sexist: precision={precisionNonSexist} recall={recallNonSexist} F1-score={f1ScoreNonSexist}')\n",
    "print(f'Weighted Average: precision={precisionWeighted} recall={recallWeighted} F1-score={f1ScoreWeighted}\\n\\n')\n",
    "\n",
    "report = classification_report(Y_test, YPredSVMNGram, output_dict=True)\n",
    "precisionSexist = report['sexist']['precision']\n",
    "recallSexist = report['sexist']['recall']\n",
    "f1ScoreSexist = report['sexist']['f1-score']\n",
    "\n",
    "precisionNonSexist = report['not sexist']['precision']\n",
    "recallNonSexist = report['not sexist']['recall']\n",
    "f1ScoreNonSexist = report['not sexist']['f1-score']\n",
    "\n",
    "precisionWeighted = report['weighted avg']['precision']\n",
    "recallWeighted = report['weighted avg']['recall']\n",
    "f1ScoreWeighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print('********** BEST MODEL: SVM Model with TF-IDF N-gram Extraction ***********\\n')\n",
    "print(f'Sexist: precision={precisionSexist} recall={recallSexist} F1-score={f1ScoreSexist}')\n",
    "print(f'Non-Sexist: precision={precisionNonSexist} recall={recallNonSexist} F1-score={f1ScoreNonSexist}')\n",
    "print(f'Weighted Average: precision={precisionWeighted} recall={recallWeighted} F1-score={f1ScoreWeighted}\\n\\n')\n",
    "\n",
    "report = classification_report(Y_test, Y_predNB, output_dict=True)\n",
    "precisionSexist = report['sexist']['precision']\n",
    "recallSexist = report['sexist']['recall']\n",
    "f1ScoreSexist = report['sexist']['f1-score']\n",
    "\n",
    "precisionNonSexist = report['not sexist']['precision']\n",
    "recallNonSexist = report['not sexist']['recall']\n",
    "f1ScoreNonSexist = report['not sexist']['f1-score']\n",
    "\n",
    "precisionWeighted = report['weighted avg']['precision']\n",
    "recallWeighted = report['weighted avg']['recall']\n",
    "f1ScoreWeighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print('********** Multinomial NB with TF-IDF N-gram Extraction ***********\\n')\n",
    "print(f'Sexist: precision={precisionSexist} recall={recallSexist} F1-score={f1ScoreSexist}')\n",
    "print(f'Non-Sexist: precision={precisionNonSexist} recall={recallNonSexist} F1-score={f1ScoreNonSexist}')\n",
    "print(f'Weighted Average: precision={precisionWeighted} recall={recallWeighted} F1-score={f1ScoreWeighted}\\n\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25ebf4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Logistic Regression Model with GloVe Extraction ***********\n",
      "\n",
      "Sexist: precision=0.5642458100558659 recall=0.3400673400673401 F1-score=0.42436974789915966\n",
      "Non-Sexist: precision=0.7839029768467475 recall=0.9011406844106464 F1-score=0.8384433962264151\n",
      "Weighted Average: precision=0.7238309892437164 recall=0.7476979742173112 F1-score=0.7252022603579115\n",
      "\n",
      "\n",
      "********** SVM Model with GloVe Extraction ***********\n",
      "\n",
      "Sexist: precision=0.4025974025974026 recall=0.20875420875420875 F1-score=0.2749445676274945\n",
      "Non-Sexist: precision=0.7478540772532188 recall=0.8833967046894804 F1-score=0.8099941894247531\n",
      "Weighted Average: precision=0.6534330529688933 recall=0.6988950276243094 F1-score=0.6636684641266078\n",
      "\n",
      "\n",
      "********** Multinomial NB with GloVe Extraction ***********\n",
      "\n",
      "Sexist: precision=0.0 recall=0.0 F1-score=0.0\n",
      "Non-Sexist: precision=0.7265193370165746 recall=1.0 F1-score=0.8416\n",
      "Weighted Average: precision=0.5278303470590031 recall=0.7265193370165746 F1-score=0.6114386740331492\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report of all models using the GloVe Extraction Feature\n",
    "\n",
    "report = classification_report(Y_test, Y_predCV, output_dict=True)\n",
    "precisionSexist = report['sexist']['precision']\n",
    "recallSexist = report['sexist']['recall']\n",
    "f1ScoreSexist = report['sexist']['f1-score']\n",
    "\n",
    "precisionNonSexist = report['not sexist']['precision']\n",
    "recallNonSexist = report['not sexist']['recall']\n",
    "f1ScoreNonSexist = report['not sexist']['f1-score']\n",
    "\n",
    "precisionWeighted = report['weighted avg']['precision']\n",
    "recallWeighted = report['weighted avg']['recall']\n",
    "f1ScoreWeighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print('********** Logistic Regression Model with GloVe Extraction ***********\\n')\n",
    "print(f'Sexist: precision={precisionSexist} recall={recallSexist} F1-score={f1ScoreSexist}')\n",
    "print(f'Non-Sexist: precision={precisionNonSexist} recall={recallNonSexist} F1-score={f1ScoreNonSexist}')\n",
    "print(f'Weighted Average: precision={precisionWeighted} recall={recallWeighted} F1-score={f1ScoreWeighted}\\n\\n')\n",
    "\n",
    "report = classification_report(Y_test, YPredSVMGlove, output_dict=True)\n",
    "precisionSexist = report['sexist']['precision']\n",
    "recallSexist = report['sexist']['recall']\n",
    "f1ScoreSexist = report['sexist']['f1-score']\n",
    "\n",
    "precisionNonSexist = report['not sexist']['precision']\n",
    "recallNonSexist = report['not sexist']['recall']\n",
    "f1ScoreNonSexist = report['not sexist']['f1-score']\n",
    "\n",
    "precisionWeighted = report['weighted avg']['precision']\n",
    "recallWeighted = report['weighted avg']['recall']\n",
    "f1ScoreWeighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print('********** SVM Model with GloVe Extraction ***********\\n')\n",
    "print(f'Sexist: precision={precisionSexist} recall={recallSexist} F1-score={f1ScoreSexist}')\n",
    "print(f'Non-Sexist: precision={precisionNonSexist} recall={recallNonSexist} F1-score={f1ScoreNonSexist}')\n",
    "print(f'Weighted Average: precision={precisionWeighted} recall={recallWeighted} F1-score={f1ScoreWeighted}\\n\\n')\n",
    "\n",
    "report = classification_report(Y_test, Y_pred_nb_glove, output_dict=True)\n",
    "precisionSexist = report['sexist']['precision']\n",
    "recallSexist = report['sexist']['recall']\n",
    "f1ScoreSexist = report['sexist']['f1-score']\n",
    "\n",
    "precisionNonSexist = report['not sexist']['precision']\n",
    "recallNonSexist = report['not sexist']['recall']\n",
    "f1ScoreNonSexist = report['not sexist']['f1-score']\n",
    "\n",
    "precisionWeighted = report['weighted avg']['precision']\n",
    "recallWeighted = report['weighted avg']['recall']\n",
    "f1ScoreWeighted = report['weighted avg']['f1-score']\n",
    "\n",
    "print('********** Multinomial NB with GloVe Extraction ***********\\n')\n",
    "print(f'Sexist: precision={precisionSexist} recall={recallSexist} F1-score={f1ScoreSexist}')\n",
    "print(f'Non-Sexist: precision={precisionNonSexist} recall={recallNonSexist} F1-score={f1ScoreNonSexist}')\n",
    "print(f'Weighted Average: precision={precisionWeighted} recall={recallWeighted} F1-score={f1ScoreWeighted}\\n\\n')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e3cf92dd",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea12c5-f018-467a-98ec-3b8008693e58",
   "metadata": {},
   "source": [
    "## Experimental results\n",
    "Please organize your results similar as the following table (you can choose other ways to display your table)\n",
    "<img src=\"example.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7827b394-47a9-4ccc-8ee3-9a9059064cff",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. What preprocessing steps do you follow?\n",
    "   \n",
    "   Your answer: I used several preprocessing commands. First, I converted all letters to lower case. Then, I removed any special symbols that are not part of the alphabet. Then, I also lemmatized the words to their original form. I initially removed all the stop words in the text as well. However, the TF-IDF N-grams extraction method did not really perform well with that. I later learned that TF-IDF takes into account the frequency of stop words when calculating the importance of words so I just let the stop words be. When I trained by models again after this change, my SVM model was able to gain an average F1 score of above 0.8. \n",
    "   \n",
    "2. How do you select the features from the inputs?\n",
    "   \n",
    "   Your answer: There was only one feature that was available, which was the text, so I did not really have to write programs or anything to select the best feature.\n",
    "   \n",
    "3. Which model you use and what is the structure of your model?\n",
    "   \n",
    "   Your answer:  I used the following three models: Logistic Regression CV, Support Vector Machine, and Multinomial NB. I chose these models because these were the ones we focused on most in our assignments. All these models fall under the supervised learning category of the machine learning model collection. The Logistic Regression CV is a regression model and the Multinomial NB is a classification model. \n",
    "   \n",
    "4. How do you train your model?\n",
    "   \n",
    "   Your answer: For the LogRegCV model, I used similar parameters, like the CV, Cs, and max-iter parameters, as the Log Reg model that we built in Homework 8. It turns out that those parameters were well-suited to represent our data. For the SVM model, it took me a while to find the best C value. If I used the logspace method to find all the best C, it would have taken a long time to complete the program. So, I figured out that the best C was around 1 and tried to find the best decimal value around 1 as well. That helped that model to become the best model out of all the other models. The training of the Multinomial NB model was pretty straightforward as there were no additional parameters that I had to input. However, when I trained the NB model with the GloVe extraction method, I had to apply a MinMaxScaler to normalize the GloVe data because the Multinomial NB does not accept negative values.\n",
    "   \n",
    "5. What is the performance of your best model?\n",
    "   \n",
    "   Your answer: My best performing model was the Support Vector Machine (SVM) model with the TF-IDF N-grams extraction method. It had a weighted average F1-score of above 0.80, which none of the other models came close to beating. The second-best was the LogReg model with the TF-IDF N-grams method, had a weighted average F1 score of 0.79.\n",
    "   \n",
    "6. What other models or feature engineering methods would you like to implement in the future?\n",
    "   \n",
    "   Your answer: I used the three existing models in the project because those were the ones I was most familiar with. However, when I was researching what models to use, I came across deep learning and neural network models as well. I wanted to try implementing them but I ran into some problems while trying to do so and was not really fully familiar with them. I think if I had more knowledge about how they worked, I will probably use them in the future.\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
